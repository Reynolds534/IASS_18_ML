{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Enginnering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A feature is an information about what we are studying. For example, the age or the gender of a person when predicting what they will buy.\n",
    "\n",
    "In the dataframe, each feature will be a column, and each example will only be characterized by its features. Features are everything you have to do the prediction.\n",
    "\n",
    "Feature engineering is about finding, creating and choosing the significant features that allow us to do the prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from generate_dataset import generate_dataset\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation with the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking for features that are correlated to the target we're predicting.\n",
    "\n",
    "Therefore, one approach is to mesure this correlation.\n",
    "\n",
    "The correlation is a float in [-1,1]. When is is closer to 0, the variables are decorrelated. When closer to 1 or -1, the variables are correlated.\n",
    "\n",
    "In what follows, find the features with a correlation lower than 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 20\n",
    "X, y = generate_dataset(n_features)\n",
    "threshold = 0.5\n",
    "# plot the correlation between each feature and y (use np.corrcoef()[0][1]), and returns\n",
    "# the list of features that have a correlation lower than the threshold\n",
    "# use plt.bar\n",
    "\n",
    "#end code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations in the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the features are highly correlated, they provide the same information.\n",
    "\n",
    "Besides, correlated features can harm the model :\n",
    "\n",
    "    1- by having one feature many times, we are adding noise to the prediction.\n",
    "    This is particularly the case for linear models (read about multicolinearity).\n",
    "    2- by masking other significant correlations between other features.\n",
    "    3- by increasing the cost of calculation\n",
    "\n",
    "When we find two features highly correlated, we simply drop one of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the features in X that have a correlation higher than 0.9\n",
    "threshold = 0.9\n",
    "# Code\n",
    "\n",
    "# End code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA\n",
    "PCA is a different approach to do feature selection.\n",
    "\n",
    "PCA is a dimensionality reduction algorithm that finds the 2D or 3D space where the data is\n",
    "as dispersed as possible.\n",
    "\n",
    "The axis of this space will be our features.\n",
    "\n",
    "It can also be used simply to have a 2D or 3D visualization of the data.\n",
    "\n",
    "PCA is particularly used with high dimensional datasets.\n",
    "\n",
    "NB: It is a necessary condition to normalize the data prior to using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_(data, Y, target_index, give_return=False):\n",
    "    from sklearn.decomposition import PCA\n",
    "    #Verified.GenerateCOLORS\n",
    "    '''\n",
    "    Inputs:\n",
    "        data: 2D np array\n",
    "        Y: 2D np array\n",
    "        target_index: int, index of the column in Y\n",
    "    Outputs:\n",
    "        None, only a plot.\n",
    "    Description:\n",
    "    Apply pca with coloring the data according to the label chosen by target_index\n",
    "    '''\n",
    "    y = Y[:,target_index]\n",
    "    pca = PCA(n_components=2)\n",
    "    X_r = pca.fit(data).transform(data)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    colors = ['red', 'blue', 'green']\n",
    "    for color, label in zip(colors, np.unique(y)):\n",
    "        plt.scatter(X_r[y == label, 0], X_r[y == label, 1], color=color, alpha=.8, label=label)\n",
    "    plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "    plt.xlabel('1st eigenvector')\n",
    "    plt.ylabel('2nd eigenvector')\n",
    "    plt.title('2D PCA of iris')\n",
    "    plt.show()\n",
    "    \n",
    "    if give_return:\n",
    "        return X_r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data \n",
    "y = iris.target.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D plots of iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./featureengineering_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the plot we find with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_(X, y, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we calculate the correlation when a feature or a target is categorical with float values?\n",
    "\n",
    "Yes. We ENCODE the categorical feature!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we are studying a movie database, and we would like include the movie genres in our correlation study.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genres = ['Comedie', 'Romantic', 'Action', 'Thriller', 'Drama', 'Horror', 'Sci-Fi']\n",
    "\n",
    "target = []\n",
    "for i in range(100):\n",
    "    target.append(Genres[np.random.randint(len(Genres))])\n",
    "    \n",
    "print target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(Genres) # we fit to all the instances. In this case, not matter what order\n",
    "target_encoded = le.transform(target)\n",
    "print 'Encoded genres:\\n', target_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the categorical feature is ordinal, make sure to conserve the order in the encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_type = ['good', 'Not satisfied', 'Very good', 'Not bad', 'Awesome!!']\n",
    "\n",
    "reviews = []\n",
    "for i in range(100):\n",
    "    reviews.append(review_type[np.random.randint(len(review_type))])\n",
    "print reviews[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode here in the right order the previous array.\n",
    "\n",
    "# End encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
